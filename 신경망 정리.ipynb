{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 신경망 학습의 전반적인 흐름\n",
    "\n",
    "1. **입력 데이터 준비**\n",
    "   - 신경망 학습의 시작은 데이터를 입력하는 것입니다. 이 데이터는 훈련을 통해 모델이 패턴을 학습할 수 있도록 도와줍니다.\n",
    "   - **입력 데이터(X)**는 피처(feature)로 이루어진 데이터이며, 신경망의 첫 번째 층(입력층)을 통해 전달됩니다.\n",
    "\n",
    "2. **전방 전파(Forward Propagation)**\n",
    "   - **입력 데이터**는 각 층의 가중치와 편향을 통과하면서 계산됩니다. 이때 비선형 활성화 함수(예: ReLU, Sigmoid, Tanh)를 사용해 다음 층으로 값을 전달합니다.\n",
    "   - 모든 층을 통과한 후, 마지막 층에서 **예측값(ŷ)**이 나오게 됩니다. 이 예측값은 모델이 입력에 대해 내린 최종 결과입니다.\n",
    "\n",
    "3. **손실 함수(Loss Function)**\n",
    "   - **손실 함수**는 모델이 얼마나 잘 예측하고 있는지 평가하는 함수입니다.\n",
    "   - 실제값(**Y**)과 모델의 예측값(**ŷ**)의 차이를 계산하여, **오차(손실)**를 수치로 나타냅니다. 예를 들어, 로지스틱 회귀에서는 **교차 엔트로피 손실(Cross-Entropy Loss)**를 자주 사용합니다.\n",
    "   - 손실 함수의 값이 작을수록 모델이 더 정확하게 예측하고 있다는 의미입니다. 이 값은 추후 기울기 계산에 사용됩니다.\n",
    "\n",
    "4. **역전파(Backpropagation)**\n",
    "   - **역전파**는 손실 함수가 계산된 후, 그 값을 바탕으로 신경망의 각 가중치와 편향에 대한 기울기를 계산하는 과정입니다.\n",
    "   - 각 가중치와 편향에 대해 **손실 함수의 변화율(기울기)**을 구합니다. 이는 손실 함수가 가중치나 편향에 따라 어떻게 변하는지를 나타냅니다.\n",
    "   - 기울기가 계산되면, 이를 통해 모델의 가중치와 편향을 업데이트할 수 있습니다.\n",
    "\n",
    "5. **경사 하강법(Gradient Descent)**\n",
    "   - 계산된 기울기를 사용하여 **경사 하강법**으로 가중치와 편향을 업데이트합니다. 경사 하강법은 손실 함수의 값이 줄어들도록 파라미터를 조금씩 조정하는 방법입니다.\n",
    "   - 기울기가 가리키는 방향으로 파라미터를 업데이트하면, 다음 반복(iteration)에서는 손실 함수의 값이 점점 줄어들게 됩니다.\n",
    "\n",
    "6. **반복(Iteration)**\n",
    "   - 신경망 학습은 이 과정을 여러 번 반복합니다. 즉, **전방 전파** → **손실 계산** → **역전파** → **파라미터 업데이트**가 여러 번 반복되며 모델이 점점 더 정확한 예측을 하도록 학습합니다.\n",
    "\n",
    "### 전체 흐름 요약:\n",
    "- **입력 데이터** → **전방 전파** → **손실 함수 계산** → **역전파** → **기울기 계산** → **가중치 업데이트** → **반복**\n",
    "\n",
    "이 과정이 끝나면, 신경망은 훈련 데이터에 맞춰 최적의 가중치와 편향을 학습하게 됩니다. 이를 통해 새로운 데이터를 입력받았을 때 더 정확한 예측을 할 수 있게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전체 과정 요약:\n",
    "### 훈련 과정 (Training):\n",
    "훈련 데이터를 사용해 모델이 가중치와 편향을 최적화합니다.\n",
    "이 단계에서는 모델이 훈련 데이터에만 노출됩니다.\n",
    "### 테스트 과정 (Testing):\n",
    "훈련이 완료된 모델에 테스트 데이터를 입력하여, 훈련되지 않은 데이터에서의 성능을 평가합니다.\n",
    "여기서 테스트 데이터는 모델이 이전에 보지 못한 새로운 데이터입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 파이토치 모듈 임포트\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 2. 데이터 준비\n",
    "# 임의의 입력 데이터 (특징 수: 3, 샘플 수: 10)와 실제 라벨\n",
    "X = torch.randn(10, 3)  # 10개의 샘플, 각 샘플에 3개의 특징\n",
    "Y = torch.randint(0, 2, (10, 1)).float()  # 10개의 실제값 (0 또는 1)\n",
    "\n",
    "# 3. 간단한 신경망 정의 (입력층 3개 뉴런, 은닉층 4개 뉴런, 출력층 1개 뉴런)\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(3, 4)  # 입력층에서 은닉층\n",
    "        self.fc2 = nn.Linear(4, 1)  # 은닉층에서 출력층\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fc1(x))  # 은닉층에 tanh 활성화 함수 사용\n",
    "        x = torch.sigmoid(self.fc2(x))  # 출력층에 sigmoid 활성화 함수 사용\n",
    "        return x\n",
    "\n",
    "# 4. 모델, 손실 함수 및 옵티마이저 설정\n",
    "model = SimpleNN()\n",
    "criterion = nn.BCELoss()  # 이진 교차 엔트로피 손실 함수\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)  # 경사 하강법 (SGD) 옵티마이저\n",
    "\n",
    "# 5. 학습 과정 (반복)\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    # 전방 전파 (예측값 계산)\n",
    "    outputs = model(X)\n",
    "\n",
    "    # 손실 계산\n",
    "    loss = criterion(outputs, Y)\n",
    "\n",
    "    # 역전파 (기울기 계산 및 가중치 업데이트)\n",
    "    optimizer.zero_grad()  # 기울기 초기화\n",
    "    loss.backward()  # 역전파로 기울기 계산\n",
    "    optimizer.step()  # 경사 하강법으로 가중치 업데이트\n",
    "\n",
    "    # 100번째 에포크마다 손실 값 출력\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# 학습 완료 후 최종 출력 확인\n",
    "with torch.no_grad():  # 기울기 계산 비활성화\n",
    "    predictions = model(X)\n",
    "    print(\"\\n예측 결과:\\n\", predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
