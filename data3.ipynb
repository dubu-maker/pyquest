{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 벡터는 1차원 배열로, 크기와 방향을 가진 수학적 객체\n",
    "\n",
    "# 텍서는 벡터를 더 일반화한 개념, 다차원 배열을 의미한다. 텐서는 0차원인 스칼라 부터 시작하여, 1차원인 벡터, 2차원인 행렬, 그리고 그 이상의 차원을 가지는 객체를 포함하는 개념"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1 노름: 벡터의 모든 성분의 절대값을 더한 값. 특정 성분만 중요한 경우 L1노름은 작은 값을 0으로 만드는 성향이 있기 때문에\n",
    "# 희소한 벡터를 찾을 때 자주 사용된다.\n",
    "\n",
    "# L2 노름: 모든 성분을 균등하게 처리하며, 부드럽고 균형 잡힌 최적화를 목표로 할 때 사용된다.\n",
    "\n",
    "# 프로테비우스 노름: 행렬의 각 원소의 제곱을 더한 후, 그 값에 제곱근을 취한 값. 행렬의 크기나 에러를 측정할 때 사용된다. 행렬을 다룰 때 L2노름과 아주 유사하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 넘파이 노름 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1 norm:  6.0\n"
     ]
    }
   ],
   "source": [
    "# L1 노름 (벡터의 모든 성분의 절대값을 더한 값) / 양수, 음수 구분하지 않는다.\n",
    "x = np. array([1, -2, 3])\n",
    "\n",
    "l1_norm = np.linalg.norm(x, ord=1)\n",
    "print(\"l1 norm: \", l1_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2 norm:  3.7416573867739413\n"
     ]
    }
   ],
   "source": [
    "# L2 노름 (벡터의 각 성분의 제곱을 합한 후 제곱근을 취한 값)\n",
    "l2_norm = np.linalg.norm(x, ord=2)\n",
    "print(\"l2 norm: \", l2_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frobenius norm:  5.477225575051661\n"
     ]
    }
   ],
   "source": [
    "# 프로테비이우스 노름 (벡터의 각 성분의 제곱을 합한 후 제곱근을 취한 값)\n",
    "A = np.array([[1, 2], [3, 4]])\n",
    "fro_norm = np.linalg.norm(A, ord='fro')\n",
    "print(\"Frobenius norm: \", fro_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.477225575051661"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1, 2], [3, 4]])\n",
    "(1**2 + 2 **2 + 3 **2 + 4 **2) ** (1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.)\n",
      "tensor(5.4772)\n",
      "tensor(5.4772)\n"
     ]
    }
   ],
   "source": [
    "# 파이토치 노름 / 넘파이는 정수로도 실행되지만 파이토치와 텐서플로는 실수로만 실행된다.\n",
    "x_pt = torch.tensor([[1, -2], [3, 4.]])\n",
    "print(torch.norm(x_pt, p=1))\n",
    "print(torch.norm(x_pt, p=2))\n",
    "print(torch.norm(x_pt, p='fro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 노름: 6.0\n",
      "L2 노름: 3.7416575\n",
      "프로테비우스 노름: 5.477226\n"
     ]
    }
   ],
   "source": [
    "# 텐서플로 노름\n",
    "x = tf.constant([1.0, -2.0, 3.0])\n",
    "\n",
    "# L1 노름 계산\n",
    "l1_norm = tf.norm(x, ord=1)\n",
    "print(\"L1 노름:\", l1_norm.numpy())\n",
    "\n",
    "# L2 노름 계산\n",
    "l2_norm = tf.norm(x, ord=2)\n",
    "print(\"L2 노름:\", l2_norm.numpy()) \n",
    "\n",
    "A = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "\n",
    "# 프로테비우스 노름 계산 (ord 생략)\n",
    "fro_norm = tf.norm(A)\n",
    "print(\"프로테비우스 노름:\", fro_norm.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 행렬에 대한 노름의 정의\n",
    "행렬에도 L1, L2 노름을 적용할 수 있지만, 그 의미가 벡터와는 다르게 정의됩니다.\n",
    "\n",
    "행렬에 대한 L1 노름: 행의 절댓값의 합 중 최대값을 의미합니다. 즉, 각 열에서 절댓값의 합을 계산한 후, 그 중에서 가장 큰 값을 반환합니다.\n",
    "행렬에 대한 L2 노름: 행렬의 가장 큰 특이값으로 정의됩니다. 즉, 행렬의 변환이 가장 많이 발생하는 크기를 나타냅니다. 벡터에서의 L2 노름이 유클리드 거리라면, 행렬에서의 L2 노름은 변환의 최대 크기입니다.\n",
    "\n",
    "이와 달리, 프로테비우스 노름은 벡터의 L2 노름을 행렬로 확장한 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# np.dot() 함수는 **내적(dot product)**과 행렬 곱셈(matrix multiplication) 모두에 사용\n",
    "\n",
    "# 내적: 벡터 간의 내적은 두 벡터의 대응하는 원소끼리 곱한 값을 모두 더한 값\n",
    "np.dot(v, w)**는 두 벡터의 내적을 계산\n",
    "\n",
    "# 행렬 곱셈은 벡터의 내적을 확장한 개념, 행렬의 행과 다른 행렬의 열의 내적을 이용하여 새로운 행렬을 만드는 방식\n",
    "np.dot(A, B)**는 행렬 곱셈을 수행합니다. 만약 A,B가 행렬이라면 행렬 곱셉이 이루어진다.\n",
    "\n",
    "# 내적은 1차원 벡터 간의 연산을 의미하고, 행렬 곱셈은 2차원 이상의 행렬에서 행과 열의 내적을 계산하는 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11],\n",
       "       [17],\n",
       "       [23]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 행렬 곱셈, 넘파이\n",
    "A = np.array([[3, 4], [5, 6], [7, 8]])\n",
    "b = np.array([[1], [2]])\n",
    "A, b\n",
    "\n",
    "np.dot(A, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11],\n",
       "        [17],\n",
       "        [23]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 행렬 곱셈, 파이토치\n",
    "A_pt = torch.tensor([[3, 4], [5, 6], [7, 8]])\n",
    "b_pt = torch.tensor([[1], [2]])\n",
    "\n",
    "torch.matmul(A_pt, b_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3), dtype=int32, numpy=array([[11, 17, 23]])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 행렬 곱셈, 텐서플로\n",
    "A_tf = tf.Variable([[3, 4], [5, 6], [7, 8]])\n",
    "b_tf = tf.constant([[1, 2]])\n",
    "\n",
    "tf.linalg.matvec(A_tf, b_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[3, 4],\n",
       "        [5, 6],\n",
       "        [7, 8]]),\n",
       " array([[1, 9],\n",
       "        [2, 0]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.array([[1, 9], [2, 0]])\n",
    "A, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[3, 4],\n",
       "        [5, 6],\n",
       "        [7, 8]]),\n",
       " array([[1, 9],\n",
       "        [2, 0]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 넘파이 배열을 파이토치, 텐서플로 텐서로 변환\n",
    "A = np.array([[3, 4], [5, 6], [7, 8]])\n",
    "B = np.array([[1, 9], [2, 0]])\n",
    "A,B "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11, 27],\n",
       "       [17, 45],\n",
       "       [23, 63]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 넘파이\n",
    "np.dot(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3, 4],\n",
       "         [5, 6],\n",
       "         [7, 8]], dtype=torch.int32),\n",
       " tensor([[1, 9],\n",
       "         [2, 0]], dtype=torch.int32))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파이토치\n",
    "A_pt = torch.from_numpy(A)\n",
    "B_pt = torch.from_numpy(B)\n",
    "A_pt, B_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11, 27],\n",
       "        [17, 45],\n",
       "        [23, 63]], dtype=torch.int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(A_pt, B_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'Variable:0' shape=(3, 2) dtype=int32, numpy=\n",
       " array([[3, 4],\n",
       "        [5, 6],\n",
       "        [7, 8]])>,\n",
       " <tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       " array([[3., 4.],\n",
       "        [5., 6.],\n",
       "        [7., 8.]], dtype=float32)>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 텐서플로\n",
    "A_tf = tf.Variable(A) # 변경 가능한\n",
    "B_tf = tf.Variable(B)\n",
    "\n",
    "A_tf2 = tf.convert_to_tensor(A, dtype=tf.float32) # 변경 불가능한\n",
    "A_tf, A_tf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[11, 27],\n",
       "       [17, 45],\n",
       "       [23, 63]])>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(A_tf, B_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.linalg.matvec: 행렬과 벡터의 곱셈\n",
    "행렬과 벡터 간의 곱셉을 수행한다.\n",
    "출력 결과는 벡터\n",
    "\n",
    "# tf.linalg.matmul: 행렬과 행렬 간의 곱셉\n",
    "두개의 행렬을 입력으로 받는다. 결과는 행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [1, 7, 8],\n",
       "       [2, 8, 9]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 대칭 행렬\n",
    "# 전치해도 행렬이 그대로 유지된다\n",
    "x_sym = np.array([[0, 1, 2], [1, 7, 8], [2, 8, 9]])  \n",
    "x_sym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [1, 7, 8],\n",
       "       [2, 8, 9]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_sym.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_sym == x_sym.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 2.],\n",
       "         [1., 7., 8.],\n",
       "         [2., 8., 9.]]),\n",
       " tensor([[0., 1., 2.],\n",
       "         [1., 7., 8.],\n",
       "         [2., 8., 9.]]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파이 토치\n",
    "I = torch.Tensor([[0, 1, 2], [1, 7, 8], [2, 8, 9]])\n",
    "I_pt = I.t()\n",
    "I_pt, I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2.],\n",
       "        [1., 7., 8.],\n",
       "        [2., 8., 9.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I_pt = I.t()\n",
    "I_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단위 행렬: 대각 성분이 1이고 나머지 성분이 0인 정방 행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]]),\n",
       " array([[1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1.]]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 넘파이\n",
    "I_3 = np.eye(3)\n",
    "I_5 = np.eye(5)\n",
    "I_3, I_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(I_3, I_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([25,  2,  5])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파이토치\n",
    "I_3_pt = torch.eye(3, dtype=torch.long) # float32 타입 / 단위형을 정수로 변환\n",
    "x_pt = torch.tensor([25, 2, 5]) # int64 타입\n",
    "# , dtype=torch.float32 / float32 타입으로 변환\n",
    "torch.matmul(I_3_pt, x_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -3]\n",
      " [ -9]\n",
      " [-15]]\n"
     ]
    }
   ],
   "source": [
    "# 2차원 배열로 y를 세로로 정의\n",
    "x = np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8]])\n",
    "y = np.array([[-1], [1], [-2]])  # 2차원 세로 벡터로 정의\n",
    "\n",
    "# 행렬 곱셈\n",
    "result = np.dot(x, y)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 2.],\n",
       "         [3., 4., 5.],\n",
       "         [6., 7., 8.]]),\n",
       " tensor([[-1.,  0.],\n",
       "         [ 1.,  1.],\n",
       "         [-2.,  2.]]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파이토치 행렬 곱셈\n",
    "x_pt = torch.Tensor([[0, 1, 2], [3, 4, 5], [6, 7, 8]])\n",
    "y_pt = torch.Tensor([[-1, 0], [1, 1], [-2, 2]])\n",
    "x_pt, y_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -3.,   5.],\n",
       "        [ -9.,  14.],\n",
       "        [-15.,  23.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(x_pt, y_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[ -3,   5],\n",
       "       [ -9,  14],\n",
       "       [-15,  23]])>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 텐서플로 행렬 곱셈\n",
    "x_tf = tf.Variable([[0, 1, 2], [3, 4, 5], [6, 7, 8]])\n",
    "y_tf = tf.Variable([[-1, 0], [1, 1], [-2, 2]])\n",
    "\n",
    "tf.matmul(x_tf, y_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.linalg.matvec(x_tf, y_tf) / 벡터와 행렬의 곱셈은 matvec 함수를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.   1. ]\n",
      " [ 1.5 -0.5]]\n"
     ]
    }
   ],
   "source": [
    "# 역행렬: 정사각 행렬 A에 대해 AB = BA = I를 만족하는 행렬 B를 A의 역행렬이라고 한다. 행렬식이 0이 아니어야 한다.\n",
    "A = np.array([[1, 2], [3, 4]])\n",
    "\n",
    "# 역행렬 계산 det(A)=ad−bc\n",
    "A_inv = np.linalg.inv(A)\n",
    "print(A_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.0000,  1.0000],\n",
      "        [ 1.5000, -0.5000]])\n"
     ]
    }
   ],
   "source": [
    "# 파이토치 역행렬\n",
    "A = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "\n",
    "A_inv = torch.inverse(A)\n",
    "print(A_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-2.0000002   1.0000001 ]\n",
      " [ 1.5000001  -0.50000006]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 텐서플로 역행렬\n",
    "A = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "\n",
    "A_inv = tf.linalg.inv(A)\n",
    "print(A_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대각행렬: 대각선 요소를 제외한 나머지 모든 요소가 0인 정사각행렬\n",
    "# 곱셈과 덧셈에서 연산이 단순해진다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 배열:\n",
      " [[4 7]\n",
      " [2 6]]\n",
      "\n",
      "B 배열 (A의 역행렬):\n",
      " [[ 0.6 -0.7]\n",
      " [-0.2  0.4]]\n",
      "\n",
      "A * B:\n",
      " [[ 1.00000000e+00 -1.11022302e-16]\n",
      " [ 1.11022302e-16  1.00000000e+00]]\n",
      "\n",
      "B * A:\n",
      " [[1.00000000e+00 6.66133815e-16]\n",
      " [0.00000000e+00 1.00000000e+00]]\n",
      "\n",
      "A * B와 단위 행렬 I가 같은가? True\n",
      "\n",
      "B * A와 단위 행렬 I가 같은가? True\n"
     ]
    }
   ],
   "source": [
    "# 역행렬 추가 ad−bc\n",
    "# 행렬 A와 역행렬 A_inv의 곱셈은 항상 단위행렬 I가 된다.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# A 배열 정의 (임의의 2x2 정사각 행렬)\n",
    "A = np.array([[4, 7],\n",
    "              [2, 6]])\n",
    "\n",
    "# A의 역행렬로 B 계산\n",
    "B = np.linalg.inv(A)\n",
    "\n",
    "# 단위 행렬 I\n",
    "I = np.eye(2) # 모든 대각선 요소가 1이고, 나머지는 모두 0인 행렬\n",
    "\n",
    "# A * B와 B * A를 계산하여 단위 행렬과 비교\n",
    "AB = np.dot(A, B)\n",
    "BA = np.dot(B, A)\n",
    "\n",
    "print(\"A 배열:\\n\", A)\n",
    "print(\"\\nB 배열 (A의 역행렬):\\n\", B)\n",
    "print(\"\\nA * B:\\n\", AB)\n",
    "print(\"\\nB * A:\\n\", BA)\n",
    "print(\"\\nA * B와 단위 행렬 I가 같은가?\", np.allclose(AB, I)) # 두 배열이 작은 오차 내에서 거의 같은지 확인\n",
    "print(\"\\nB * A와 단위 행렬 I가 같은가?\", np.allclose(BA, I))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 넘파이\n",
    "A_inv = np.linalg.inv(A)\n",
    "\n",
    "# 파이토치\n",
    "A_inv = torch.inverse(A)\n",
    "\n",
    "# 텐서플로\n",
    "A_inv = tf.linalg.inv(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대각 행렬: 연산이 간단하고 효율적인 특징, 대각선 이외이 모든 요소가 0인 정사각 행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy Diagonal Matrix:\n",
      " [[1 0 0 0]\n",
      " [0 2 0 0]\n",
      " [0 0 3 0]\n",
      " [0 0 0 4]]\n",
      "\n",
      "PyTorch Diagonal Matrix:\n",
      " tensor([[1, 0, 0, 0],\n",
      "        [0, 2, 0, 0],\n",
      "        [0, 0, 3, 0],\n",
      "        [0, 0, 0, 4]])\n",
      "\n",
      "TensorFlow Diagonal Matrix:\n",
      " tf.Tensor(\n",
      "[[1 0 0 0]\n",
      " [0 2 0 0]\n",
      " [0 0 3 0]\n",
      " [0 0 0 4]], shape=(4, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "# 넘파이 대각행렬\n",
    "D = np.diag([1, 2, 3, 4])\n",
    "\n",
    "# 파이토치 대각행렬\n",
    "D_pt = torch.diag(torch.tensor([1, 2, 3, 4]))\n",
    "\n",
    "# 텐서플로 대각행렬\n",
    "D_tf = tf.linalg.diag([1, 2, 3, 4])\n",
    "\n",
    "print(\"Numpy Diagonal Matrix:\\n\", D)\n",
    "print(\"\\nPyTorch Diagonal Matrix:\\n\", D_pt)\n",
    "print(\"\\nTensorFlow Diagonal Matrix:\\n\", D_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy 직교 행렬:\n",
      " [[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n",
      "임의의 3x3 직교 행렬 (QR 분해 사용):\n",
      " [[-0.35727565  0.93012852  0.08494137]\n",
      " [-0.71566772 -0.2141883  -0.664788  ]\n",
      " [-0.60014483 -0.29830236  0.74218723]]\n"
     ]
    }
   ],
   "source": [
    "# 직교 행렬: 행 벡터들과 열 벡터들이 서로 직교인 정사각행렬\n",
    "# 전치 행렬이 곧 역행렬\n",
    "\n",
    "# 단위 행렬은 직교 행렬의 한 예입니다.\n",
    "Q = np.eye(3)  # 3x3 단위 행렬\n",
    "print(\"Numpy 직교 행렬:\\n\", Q)\n",
    "\n",
    "# 임의의 직교 행렬을 생성 (QR 분해 사용)\n",
    "A = np.random.rand(3, 3)\n",
    "Q, R = np.linalg.qr(A)\n",
    "print(\"임의의 3x3 직교 행렬 (QR 분해 사용):\\n\", Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이토치 직교 행렬\n",
    "# 단위 행렬 (직교 행렬)\n",
    "Q = torch.eye(3)  # 3x3 단위 행렬\n",
    "print(\"PyTorch 직교 행렬:\\n\", Q)\n",
    "\n",
    "# QR 분해를 사용하여 직교 행렬 생성\n",
    "A = torch.rand(3, 3)\n",
    "Q, R = torch.qr(A)\n",
    "print(\"임의의 3x3 직교 행렬 (QR 분해 사용):\\n\", Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서플로 직교 행렬\n",
    "# 단위 행렬 (직교 행렬)\n",
    "Q = tf.eye(3)  # 3x3 단위 행렬\n",
    "print(\"TensorFlow 직교 행렬:\\n\", Q)\n",
    "\n",
    "# QR 분해를 사용하여 직교 행렬 생성\n",
    "A = tf.random.normal((3, 3))\n",
    "Q, R = tf.linalg.qr(A)\n",
    "print(\"임의의 3x3 직교 행렬 (QR 분해 사용):\\n\", Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 넘파이 직교행렬\n",
    "Q, R = np.linalg.qr(A)\n",
    "\n",
    "# 파이토치 직교행렬\n",
    "Q, R = torch.qr(A)\n",
    "\n",
    "# 텐서플로 직교행렬\n",
    "Q, R = tf.linalg.qr(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'두 벡터의 내적이 0이면 두 벡터는 직교한다'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 연습문제 1: 종이와 펜을 사용하여 𝐼3 의 두 열을 내적(dots product)하여, 두 열이 서로 직교함을 증명하시오.\n",
    "i3 = np.eye(3)\n",
    "i3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3x3 단위 행렬\n",
    "i3 = np.eye(3)\n",
    "\n",
    "# i3의 전치 행렬과 i3를 곱해서 내적을 한 번에 계산\n",
    "dot_matrix = np.dot(i3.T, i3)\n",
    "\n",
    "print(\"각 열 벡터 간의 내적 행렬:\")\n",
    "print(dot_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 3x3 단위 행렬\n",
    "i3 = np.eye(3)\n",
    "\n",
    "# 열 벡터 간 내적 계산\n",
    "dot_1_2 = np.dot(i3[:, 0], i3[:, 1])  # 첫 번째 열과 두 번째 열\n",
    "dot_1_3 = np.dot(i3[:, 0], i3[:, 2])  # 첫 번째 열과 세 번째 열\n",
    "dot_2_3 = np.dot(i3[:, 1], i3[:, 2])  # 두 번째 열과 세 번째 열\n",
    "\n",
    "print(f\"첫 번째 열과 두 번째 열의 내적: {dot_1_2}\")\n",
    "print(f\"첫 번째 열과 세 번째 열의 내적: {dot_1_3}\")\n",
    "print(f\"두 번째 열과 세 번째 열의 내적: {dot_2_3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.66666667,  0.33333333,  0.66666667],\n",
       "       [-0.66666667,  0.66666667,  0.33333333],\n",
       "       [ 0.33333333,  0.66666667, -0.66666667]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이번에는 행렬 K를 사용하여 연습문제 1번에서 3번까지를 다시 수행하여, 𝐾 직교 행렬인지 평가하시오.\n",
    "K = np.array([[2/3, 1/3, 2/3], [-2/3, 2/3, 1/3], [1/3, 2/3, -2/3]])\n",
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 벡터 정의\n",
    "a = [a1, a2, a3]\n",
    "b = [b1, b2, b3]\n",
    "\n",
    "# 내적 수식 계산\n",
    "dot_product = a[0] * b[0] + a[1] * b[1] + a[2] * b[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 넘파이 내적 계산\n",
    "K_dot = np.dot(K.T, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이토치 내적 계산\n",
    "'1차원 벡터 내적'\n",
    "a = torch.tensor([a1, a2, a3])\n",
    "b = torch.tensor([b1, b2, b3])\n",
    "K_pt = torch.dot(a, b)\n",
    "\n",
    "'2차원 이상의 행렬 곱셈'\n",
    "A = torch.tensor([[1, 2], [3, 4]])\n",
    "B = torch.tensor([[5, 6], [7, 8]])\n",
    "result = torch.matmul(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서플로 내적 계산\n",
    "'1차원 벡터 내적'\n",
    "a = tf.constant([a1, a2, a3])\n",
    "b = tf.constant([b1, b2, b3])\n",
    "dot_product = tf.tensordot(a, b, axes=1)\n",
    "\n",
    "'2차원 행결 곱셈 (matmul 함수 사용)'\n",
    "result = tf.matmul(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "넘파이: np.dot(a, b)\n",
    "파이토치: torch.dot(a, b) (1차원 벡터), torch.matmul(A, B) (행렬 곱)\n",
    "텐서플로: tf.tensordot(a, b, axes=1) (1차원 벡터), tf.matmul(A, B) (행렬 곱)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
